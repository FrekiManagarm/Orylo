# Story 4.4: Feedback Loop & Apprentissage des Overrides

**Epic**: Epic 4 - SystÃ¨me de DÃ©cisions AssistÃ© par IA  
**Story Points**: 10  
**Status**: ðŸ“‹ Draft

---

## Story

**As a** system,  
**I want** to track merchant overrides (accept/reject suggestions) and learn from them,  
**so that** future suggestions become more accurate and aligned with merchant preferences.

---

## Acceptance Criteria

1. **AC1**: Track all merchant actions on AI suggestions (accepted, rejected, modified) - triggered from `POST /api/suggestions/[id]/accept` and `/reject` endpoints (Story 4.1)
2. **AC2**: Store feedback in `ai_feedback` table with context: `suggestionId`, `detectionId`, `suggestionType`, `originalConfidence`, `detectionContext` (partial: amount, customerEmail, decision, riskScore)
3. **AC3**: Optional merchant reason field when rejecting suggestion - input via `feedback-reason-dialog.tsx` component, stored in `ai_feedback.merchantReason`
4. **AC4**: Feedback data used to improve suggestion confidence scores - Trigger.dev scheduled job `analyze-feedback` (daily) analyzes feedback, updates confidence thresholds stored in Redis
5. **AC5**: A/B testing framework: Compare suggestion acceptance rates by time period (weekly), before/after model updates, generate reports showing improvement
6. **AC6**: Dashboard metric: "AI Suggestion Accuracy" (acceptance rate = accepted / (accepted + rejected)) displayed in `ai-metrics-card.tsx` component in Settings page
7. **AC7**: Privacy: Feedback data anonymized for model improvement (opt-in checkbox in Settings) - remove PII (emails, customer IDs) via `feedback-anonymizer.ts`
8. **AC8**: Integration test: Verify feedback tracking (accept/reject actions create `ai_feedback` records), model update triggers (scheduled job updates thresholds), anonymization logic

---

## Tasks / Subtasks

- [ ] **Task 1**: Database schema for AI feedback (AC1, AC2, AC3)
  - [ ] Create `ai_feedback` table migration (Drizzle)
  - [ ] Fields: `id`, `suggestionId`, `merchantAction` (accepted/rejected/modified), `merchantReason`, `context` (JSON), `createdAt`
  - [ ] Add foreign key to `ai_suggestions` table
  - [ ] Add index on `suggestionId`, `merchantAction`, `createdAt`

- [ ] **Task 2**: Feedback tracking API (AC1, AC2, AC3)
  - [ ] Update `POST /api/suggestions/[id]/accept` (Story 4.1) to track feedback
    - [ ] After applying whitelist/blacklist, create `ai_feedback` record with `merchantAction='accepted'`
  - [ ] Update `POST /api/suggestions/[id]/reject` (Story 4.1) to track feedback with reason
    - [ ] Accept optional `merchantReason` in request body
    - [ ] Create `ai_feedback` record with `merchantAction='rejected'`, `merchantReason`
  - [ ] Create `POST /api/suggestions/[id]/feedback` endpoint (explicit feedback for modified suggestions)
  - [ ] Store feedback with full context:
    - [ ] `suggestionId` (from `ai_suggestions` table)
    - [ ] `detectionId` (from suggestion context)
    - [ ] `suggestionType` (whitelist/blacklist/rule)
    - [ ] `originalConfidence` (from suggestion)
    - [ ] `detectionContext` (partial: amount, customerEmail, decision, riskScore)

- [ ] **Task 3**: Feedback analysis engine (AC4)
  - [ ] Create `lib/ai/feedback-analyzer.ts`
  - [ ] Analyze feedback patterns: which suggestions accepted/rejected
  - [ ] Calculate suggestion accuracy: accepted / (accepted + rejected)
  - [ ] Identify patterns: low-confidence suggestions more rejected, etc.
  - [ ] Update suggestion confidence scores based on feedback

- [ ] **Task 4**: A/B testing framework (AC5)
  - [ ] Create `lib/ai/ab-testing.ts`
  - [ ] Track suggestion acceptance rates by time period (weekly)
  - [ ] Compare acceptance rates: before/after model updates
  - [ ] Generate A/B test reports: "Acceptance rate improved from 55% to 68%"

- [ ] **Task 5**: Dashboard metrics (AC6)
  - [ ] Create `GET /api/organizations/[id]/ai-metrics` endpoint
  - [ ] Calculate: AI Suggestion Accuracy (acceptance rate)
  - [ ] Calculate: Total suggestions, accepted, rejected, modified
  - [ ] Create `components/ai-metrics-card.tsx` component
  - [ ] Display metrics in Settings page or Dashboard

- [ ] **Task 6**: Privacy & anonymization (AC7)
  - [ ] Create opt-in checkbox in Settings: "Share feedback for model improvement"
  - [ ] Anonymize feedback data: Remove PII (emails, customer IDs)
  - [ ] Create `lib/ai/feedback-anonymizer.ts` for data sanitization
  - [ ] Store anonymized feedback separately (optional export for model training)

- [ ] **Task 7**: Model update triggers (AC4, AC8)
  - [ ] Create Trigger.dev scheduled job: `analyze-feedback` (daily)
  - [ ] Job analyzes feedback, updates suggestion confidence thresholds
  - [ ] Job generates A/B test report
  - [ ] Store model version and update history

- [ ] **Task 8**: Integration tests (AC8)
  - [ ] Test feedback tracking on accept/reject actions
  - [ ] Test feedback analysis logic
  - [ ] Test A/B testing framework
  - [ ] Test anonymization logic

---

## Dependencies

**Depends on**:
- Story 4.1: `ai_suggestions` table, suggestion accept/reject endpoints
- Epic 3: Trigger.dev configured (ADR-006) for scheduled job, Redis for caching metrics

**Blocks**:
- None (final story in Epic 4)

**Can be developed after**:
- Story 4.1 must be completed first (needs suggestion endpoints)
- Stories 4.2 and 4.3 can be developed in parallel

---

## Dev Notes

### Relevant Architecture

**Feedback Data Structure**:
```typescript
interface AIFeedback {
  suggestionId: string;
  merchantAction: 'accepted' | 'rejected' | 'modified';
  merchantReason?: string; // Optional when rejecting
  context: {
    detectionId: string;
    suggestionType: 'whitelist' | 'blacklist' | 'rule';
    originalConfidence: number;
    detectionContext: Partial<DetectionContext>;
  };
  timestamp: Date;
}
```

**Feedback Analysis**:
```typescript
interface FeedbackAnalysis {
  suggestionId: string;
  totalFeedback: number;
  accepted: number;
  rejected: number;
  modified: number;
  acceptanceRate: number; // accepted / total
  averageConfidence: number;
  patterns: {
    lowConfidenceRejected: number; // <0.6 confidence rejected
    highConfidenceAccepted: number; // >0.8 confidence accepted
  };
}
```

**Database Schema**:
```typescript
// packages/database/src/schema/ai-feedback.ts
import { pgTable, text, timestamp, boolean, jsonb, index } from "drizzle-orm/pg-core";
import { aiSuggestions } from "./ai-suggestions";
import { organizations } from "./organizations";

export const aiFeedback = pgTable('ai_feedback', {
  id: text('id').primaryKey().$defaultFn(() => crypto.randomUUID()),
  suggestionId: text('suggestion_id')
    .notNull()
    .references(() => aiSuggestions.id, { onDelete: 'cascade' }),
  organizationId: text('organization_id')
    .notNull()
    .references(() => organizations.id, { onDelete: 'cascade' }),
  merchantAction: text('merchant_action', { enum: ['accepted', 'rejected', 'modified'] }).notNull(),
  merchantReason: text('merchant_reason'), // Optional
  context: jsonb('context').notNull(), // AIFeedback context (detectionId, suggestionType, originalConfidence, detectionContext)
  anonymized: boolean('anonymized').default(false).notNull(), // If shared for model improvement
  createdAt: timestamp('created_at').defaultNow().notNull(),
});

// Indexes for performance
export const aiFeedbackIndexes = {
  suggestionId: index('ai_feedback_suggestion_id_idx').on(aiFeedback.suggestionId),
  merchantAction: index('ai_feedback_merchant_action_idx').on(aiFeedback.merchantAction),
  createdAt: index('ai_feedback_created_at_idx').on(aiFeedback.createdAt),
  organizationId: index('ai_feedback_organization_id_idx').on(aiFeedback.organizationId),
};
```

**Model Update Logic**:
```typescript
// lib/ai/feedback-analyzer.ts
async function updateSuggestionConfidence(
  organizationId: string,
  feedbackAnalysis: FeedbackAnalysis
): Promise<void> {
  // Analyze feedback patterns
  // If acceptance rate <50% for confidence >0.8 â†’ lower threshold (suggestions too aggressive)
  // If acceptance rate >80% for confidence <0.6 â†’ raise threshold (suggestions too conservative)
  
  // Update suggestion engine parameters (store in Redis or DB config table)
  // Example: Adjust confidence thresholds based on merchant's acceptance patterns
  const adjustedThreshold = calculateAdjustedThreshold(feedbackAnalysis);
  await redis.set(`suggestion_threshold:${organizationId}`, adjustedThreshold, 'EX', 86400);
}
```

**A/B Testing**:
```typescript
interface ABTestResult {
  period: 'before' | 'after';
  acceptanceRate: number;
  totalSuggestions: number;
  improvement: number; // percentage
}
```

**Integration Points**:
- Uses existing `ai_suggestions` table (Story 4.1)
- Integrates with suggestion accept/reject endpoints (Story 4.1)
- Uses Trigger.dev for scheduled analysis (ADR-006)
- Uses Redis for caching metrics (Epic 3)

**Privacy Considerations**:
- Opt-in for sharing feedback (GDPR compliant)
- Anonymize PII before storage/export
- Clear data retention policy (90 days, same as detections)

### Source Tree Context

```
apps/web/
â”œâ”€â”€ trigger/
â”‚   â””â”€â”€ jobs/
â”‚       â””â”€â”€ analyze-feedback.job.ts          # Scheduled daily analysis
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ai/
â”‚       â”œâ”€â”€ feedback-analyzer.ts              # Feedback analysis & model updates
â”‚       â”œâ”€â”€ feedback-anonymizer.ts            # PII removal
â”‚       â””â”€â”€ ab-testing.ts                     # A/B testing framework
â”œâ”€â”€ app/
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ suggestions/
â”‚       â”‚   â””â”€â”€ [id]/
â”‚       â”‚       â””â”€â”€ feedback/
â”‚       â”‚           â””â”€â”€ route.ts             # POST explicit feedback
â”‚       â””â”€â”€ organizations/
â”‚           â””â”€â”€ [id]/
â”‚               â””â”€â”€ ai-metrics/
â”‚                   â””â”€â”€ route.ts             # GET AI metrics
â””â”€â”€ components/
    â”œâ”€â”€ ai-metrics-card.tsx                   # Metrics display
    â””â”€â”€ feedback-reason-dialog.tsx            # Optional reason input
```

---

## Testing

### Unit Tests
- **File**: `apps/web/lib/ai/feedback-analyzer.test.ts`
- **Tests**:
  - Feedback analysis logic
  - Acceptance rate calculation
  - Model update triggers
  - A/B testing framework

### Integration Tests
- **File**: `apps/web/lib/ai/__tests__/feedback-analyzer.integration.test.ts`
- **Tests**:
  - Full feedback tracking flow
  - Database storage and retrieval
  - Model update job execution
  - Anonymization logic

### E2E Tests
- **File**: `e2e/ai-feedback-loop.spec.ts` (Playwright)
- **Tests**:
  - Accept suggestion â†’ feedback tracked
  - Reject suggestion with reason â†’ feedback tracked
  - Metrics displayed in dashboard
  - Opt-in privacy setting

### Testing Standards
- Framework: Vitest (unit), Playwright (E2E)
- Coverage target: â‰¥80% for feedback logic
- Test with mock feedback data
- Test edge cases (no feedback, conflicting patterns)

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-26 | 1.0 | Story created | Sarah (PO) |

---

## Dev Agent Record

(To be populated during implementation)

---

## QA Results

(To be populated by QA agent after testing)
