# Story 4.2: Explications IA des D√©cisions de Fraude

**Epic**: Epic 4 - Syst√®me de D√©cisions Assist√© par IA  
**Story Points**: 8  
**Status**: üîÑ InProgress

---

## Story

**As a** merchant,  
**I want** to understand why a transaction was flagged as fraudulent in plain French language,  
**so that** I can make informed decisions and learn from detection patterns.

---

## Acceptance Criteria

1. **AC1**: Explanation generated asynchronously after detection (non-blocking via Trigger.dev job) - webhook returns <250ms, explanation generated in background
2. **AC2**: LLM API call (OpenAI GPT-4o-mini primary, Anthropic Claude backup) with detection context from `fraud_detections.detectorResults`
3. **AC3**: Explanation includes: which detectors triggered (from `detectorResults`), why they flagged (detector scores and reasons), risk factors identified (riskScore, decision)
4. **AC4**: Explanation displayed in `detection-details-dialog.tsx` with loading skeleton while generating, "Generating explanation..." badge if pending
5. **AC5**: Language: French (LLM prompt in French, system message: "Tu es un expert..."), fallback to English template if LLM unavailable
6. **AC6**: Performance: Generation <2s async (Trigger.dev job latency), displayed progressively via SSE (ADR-008: backend polls DB every 5s, frontend receives updates via EventSource)
7. **AC7**: Error handling: Fallback to template-based explanation if LLM fails (from `lib/ai/explanation-templates.ts`) - lists detector names and scores
8. **AC8**: Cost control: Rate limiting (10 explanations/minute per organization via Redis), caching similar detections (same detector pattern ‚Üí reuse explanation)

---

## Tasks / Subtasks

- [x] **Task 1**: Create Trigger.dev job for AI explanation (AC1, AC2)
  - [x] Create `trigger/jobs/ai-explanation.job.ts` (ADR-006)
  - [x] Job accepts: `detectionId`, `context`, `factors`, `priority`
  - [x] Build prompt with detection context (detector results, scores, metadata)
  - [x] Call OpenAI/Anthropic API with French language instruction
  - [x] Store explanation in `ai_explanations` table

- [x] **Task 2**: Database schema for AI explanations (AC3)
  - [x] Create `ai_explanations` table migration (Drizzle)
  - [x] Fields: `id`, `detectionId`, `explanation` (text), `generatedAt`, `model`, `tokensUsed`, `latency`, `triggerJobId`
  - [x] Add foreign key to `fraud_detections` table

- [x] **Task 3**: Trigger explanation job after detection saved (AC1)
  - [x] Update `lib/fraud/detect-fraud.ts` in `saveFraudDetection()` function
  - [x] After detection stored in `fraud_detections` table, trigger `generateAIExplanation.trigger()` (non-blocking, fire-and-forget)
  - [x] Set priority: HIGH for BLOCK, NORMAL for REVIEW/ALLOW
  - [x] Pass detection context: `detectionId`, `detectorResults`, `riskScore`, `decision`, `customerEmail`, `amount`, `cardCountry`, `customerIp`
  - [x] **Note**: Trigger is called from `saveFraudDetection()` which is called by `detectFraud()`, ensuring detection is saved before explanation job starts
  - [x] Webhook response already returns immediately (<250ms) - explanation generation is fully async

- [x] **Task 4**: API endpoint to fetch explanation (AC4)
  - [x] Create `GET /api/detections/[id]/explanation` endpoint
  - [x] Validate `detectionId` with Zod schema (UUID format, ADR-010)
  - [x] Verify Better Auth session (pattern: `auth.api.getSession()`)
  - [x] Verify detection belongs to user's organization (RLS check)
  - [x] Apply rate limiting: 100 req/min per organization (ADR-010)
  - [x] Return explanation if generated, or status "pending" if still generating
  - [x] Return fallback template explanation if LLM failed

- [x] **Task 5**: UI component for explanation display (AC4, AC5)
  - [x] Create `components/ai-explanation.tsx` component
  - [x] **Design**: Card layout with border (Shadcn Card component)
  - [x] **Styling**: 
    - Background: `bg-muted/50` (light mode), `bg-muted/20` (dark mode)
    - Border: `border-border`
    - Padding: `p-4`
    - Typography: Explanation text uses `text-sm` with `leading-relaxed`
  - [x] **Loading state**: Skeleton component (Shadcn Skeleton) matching explanation text height
  - [x] **Sanitization**: Sanitize explanation text with DOMPurify before display (XSS prevention, ADR-010)
  - [x] Show loading skeleton while generating
  - [x] Display explanation in French (with language indicator badge: "FR" badge, variant 'secondary')
  - [x] **SSE Integration**: Use `useSSE` hook to listen for `explanation.updated` events (ADR-008)
    - Poll endpoint every 2s if SSE not available (fallback)
  - [x] Integrate into `detection-details-dialog.tsx` (position: After Detector Results section, before Trust Score)
  - [x] Show "Generating explanation..." badge if pending (Shadcn Badge, variant 'secondary', icon: Loader2 spinning)
  - [x] **Responsive**: Mobile-friendly layout (stack vertically on <768px)
  - [x] **Accessibility**: ARIA labels, keyboard navigation support

- [x] **Task 6**: Fallback template explanations (AC7)
  - [x] Create `lib/ai/explanation-templates.ts`
  - [x] Template-based explanation: List detectors triggered + scores
  - [x] Use if LLM fails or unavailable
  - [x] Format: "Cette transaction a √©t√© signal√©e par: [detector names]. Score de risque: [score]"

- [x] **Task 7**: Cost control & caching (AC8)
  - [x] Rate limiting: Max 10 explanations/minute per organization
  - [x] Cache similar detections (same detector pattern) ‚Üí reuse explanation
  - [x] Monitor API costs (PostHog event: `ai_explanation_generated`, `tokens_used`)
  - [ ] Alert if monthly cost >‚Ç¨200 (TODO: Requires PostHog integration)

- [x] **Task 8**: Integration tests (AC2, AC7)
  - [x] Test Trigger.dev job execution (mocked LLM)
  - [x] Test fallback to template if LLM fails
  - [x] Test rate limiting logic
  - [x] Test explanation display in UI

---

## Dependencies

**Depends on**:
- Epic 1: `fraud_detections` table with `detectorResults` field
- Epic 3: Trigger.dev configured (ADR-006), Redis for rate limiting
- Infrastructure: OpenAI/Anthropic API keys configured (see `docs/epics/epic-4-infrastructure-setup.md`)

**Blocks**:
- None (can be developed independently)

**Can be developed in parallel with**:
- Story 4.1 (Suggestions) - no shared dependencies
- Story 4.3 (Rule recommendations) - no shared dependencies
- Story 4.4 (Feedback loop) - no shared dependencies

---

## Dev Notes

### Relevant Architecture

**Trigger.dev Job** (ADR-006):
```typescript
// trigger/jobs/ai-explanation.job.ts
import { task } from "@trigger.dev/sdk/v3";
import { openai } from "@/lib/openai";

export const generateAIExplanation = task({
  id: "generate-ai-explanation",
  retry: { maxAttempts: 3, factor: 2 },
  queue: { name: "ai-explanation", concurrencyLimit: 10 },
  run: async (payload: {
    detectionId: string;
    context: TransactionContext;
    factors: FraudFactor[];
    priority: 'HIGH' | 'NORMAL';
  }) => {
    const prompt = buildExplanationPrompt(payload.context, payload.factors);
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        { role: "system", content: "Tu es un expert en d√©tection de fraude..." },
        { role: "user", content: prompt },
      ],
      temperature: 0.3,
    });
    
    const explanation = completion.choices[0].message.content || "";
    
    // Store in ai_explanations table (not in fraud_detections directly)
    await db.insert(aiExplanations).values({
      detectionId: payload.detectionId,
      organizationId: payload.context.organizationId,
      explanation,
      model: "gpt-4o-mini",
      tokensUsed: completion.usage?.total_tokens,
      latency: Date.now() - startTime,
      triggerJobId: run.id,
    });
    
    return { success: true, explanation };
  },
});
```

**Prompt Template**:
```
Tu es un expert en d√©tection de fraude. Analyse cette d√©tection et explique en fran√ßais (2-3 phrases) pourquoi cette transaction a √©t√© signal√©e.

Transaction:
- Montant: {amount} {currency}
- Client: {customerEmail}
- Pays carte: {cardCountry}
- IP: {customerIp}

D√©tecteurs d√©clench√©s:
{detector_results_formatted}

Score de risque: {riskScore}/100
D√©cision: {decision}

Explique en fran√ßais pourquoi cette transaction est suspecte, en mentionnant les facteurs de risque principaux. Sois concis (2-3 phrases maximum).
```

**Detector Results Format**:
```typescript
// DetectorResult type from @orylo/fraud-engine
interface DetectorResult {
  detectorId: string; // e.g., 'velocity', 'geolocation', 'trust-score'
  decision: 'ALLOW' | 'REVIEW' | 'BLOCK';
  score: number; // 0-100
  metadata?: Record<string, unknown>; // Detector-specific data
  reason?: string; // Human-readable reason (optional)
}

// Format detector results for prompt
const detectorResultsFormatted = detectorResults
  .map(d => {
    const reason = d.reason || d.metadata?.reason || 'D√©tecteur d√©clench√©';
    return `- ${d.detectorId}: Score ${d.score}/100, D√©cision: ${d.decision} (${reason})`;
  })
  .join('\n');

// Example output:
// - velocity: Score 85/100, D√©cision: BLOCK (Trop de transactions en peu de temps)
// - geolocation: Score 60/100, D√©cision: REVIEW (Pays inhabituel)
// - trust-score: Score 25/100, D√©cision: BLOCK (Score de confiance faible)
```

**Database Schema**:
```typescript
// packages/database/src/schema/ai-explanations.ts
import { pgTable, text, timestamp, integer, index } from "drizzle-orm/pg-core";
import { fraudDetections } from "./fraud-detections";
import { organizations } from "./organizations";

export const aiExplanations = pgTable('ai_explanations', {
  id: text('id').primaryKey().$defaultFn(() => crypto.randomUUID()),
  detectionId: text('detection_id')
    .notNull()
    .references(() => fraudDetections.id, { onDelete: 'cascade' }),
  organizationId: text('organization_id')
    .notNull()
    .references(() => organizations.id, { onDelete: 'cascade' }),
  explanation: text('explanation').notNull(),
  generatedAt: timestamp('generated_at').defaultNow().notNull(),
  model: text('model').notNull(), // 'gpt-4o-mini' or 'claude-3-haiku'
  tokensUsed: integer('tokens_used'),
  latency: integer('latency'), // ms
  triggerJobId: text('trigger_job_id'),
  createdAt: timestamp('created_at').defaultNow().notNull(),
});

// Indexes for performance
export const aiExplanationsIndexes = {
  detectionId: index('ai_explanations_detection_id_idx').on(aiExplanations.detectionId),
  organizationId: index('ai_explanations_organization_id_idx').on(aiExplanations.organizationId),
};
```

**Integration Points**:
- Uses Trigger.dev for async processing (ADR-006)
- **Trigger Location**: Called from `saveFraudDetection()` in `lib/fraud/detect-fraud.ts` after detection is saved to DB
- Integrates with `detection-details-dialog.tsx` (Epic 2)
- Uses existing `fraud_detections` table (Epic 1)
- Uses Redis for rate limiting (Epic 3, ADR-003)
- **Real-Time Updates**: Uses SSE (ADR-008) - backend polls DB every 5s, frontend receives via EventSource
- **ADR References**: ADR-006 (Background Jobs), ADR-008 (Real-Time Strategy), ADR-010 (Security Architecture)

**Cost Control Strategy**:
- Use GPT-4o-mini (cheaper than GPT-4)
- Cache explanations for similar detections (same detector pattern)
- Rate limit: 10/minute per organization (Redis-based, ADR-003)
- Monitor costs via PostHog events (`ai_explanation_generated`, `tokens_used`)
- Fallback to templates if budget exceeded (>‚Ç¨200/month)
- **Cache Key Pattern**: `explanation:pattern:{detectorIdsHash}` (hash of sorted detector IDs)

**Security & Multi-Tenancy** (ADR-010):
- All API endpoints verify Better Auth session (pattern: `auth.api.getSession()`)
- Extract `organizationId` from session for multi-tenancy
- Verify explanation belongs to user's organization (via `detectionId` ‚Üí `fraud_detections.organizationId`)
- Return 401 if no session, 403 if wrong organization
- **Input Validation (Zod schemas)**:
  ```typescript
  // lib/validation/ai-explanations.ts
  import { z } from "zod";
  
  export const DetectionIdSchema = z.string().uuid("Invalid detection ID format");
  
  // Usage in API route
  const validated = DetectionIdSchema.parse(detectionId);
  ```
- **XSS Prevention**: Sanitize explanation text with DOMPurify before display in UI
- Validate `detectionId` format (UUID) and existence in DB

### Source Tree Context

```
apps/web/
‚îú‚îÄ‚îÄ trigger/
‚îÇ   ‚îî‚îÄ‚îÄ jobs/
‚îÇ       ‚îî‚îÄ‚îÄ ai-explanation.job.ts      # Trigger.dev job
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ ai/
‚îÇ       ‚îú‚îÄ‚îÄ explanation-prompt.ts      # Prompt building
‚îÇ       ‚îî‚îÄ‚îÄ explanation-templates.ts    # Fallback templates
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îî‚îÄ‚îÄ detections/
‚îÇ           ‚îî‚îÄ‚îÄ [id]/
‚îÇ               ‚îî‚îÄ‚îÄ explanation/
‚îÇ                   ‚îî‚îÄ‚îÄ route.ts       # GET explanation
‚îî‚îÄ‚îÄ components/
    ‚îú‚îÄ‚îÄ ai-explanation.tsx             # Explanation display component
    ‚îî‚îÄ‚îÄ detection-details-dialog.tsx   # Integrate explanation
```

---

## Testing

### Unit Tests
- **File**: `apps/web/lib/ai/explanation-prompt.test.ts`
- **Tests**:
  - Prompt building with detection context
  - Template fallback generation
  - Rate limiting logic

### Integration Tests
- **File**: `apps/web/trigger/jobs/__tests__/ai-explanation.integration.test.ts`
- **Tests**:
  - Trigger.dev job execution (mocked LLM)
  - Database storage of explanation
  - Fallback to template on LLM failure

### E2E Tests
- **File**: `e2e/ai-explanation.spec.ts` (Playwright)
- **Tests**:
  - Explanation appears in detection dialog
  - Loading state while generating
  - Fallback template displayed if LLM fails

### Testing Standards
- Framework: Vitest (unit), Playwright (E2E)
- Coverage target: ‚â•80% for explanation logic
- Mock LLM API calls (deterministic tests)
- Test error scenarios (LLM timeout, rate limit)

**Mock Data Structure - fraud_detections**:
```typescript
// Required: Mock detection with detectorResults
const mockFraudDetection = {
  id: 'det_001',
  organizationId: 'org_001',
  paymentIntentId: 'pi_001',
  customerId: 'cus_stripe_001',
  customerEmail: 'customer@example.com',
  amount: 5000, // ‚Ç¨50.00
  currency: 'eur',
  decision: 'BLOCK',
  score: 85,
  detectorResults: [
    {
      detectorId: 'velocity',
      decision: 'BLOCK',
      score: 85,
      metadata: {
        txCount: 10,
        timeWindow: '1h',
        reason: 'Trop de transactions en peu de temps',
      },
    },
    {
      detectorId: 'geolocation',
      decision: 'REVIEW',
      score: 60,
      metadata: {
        ipCountry: 'US',
        cardCountry: 'FR',
        reason: 'Pays inhabituel',
      },
    },
    {
      detectorId: 'trust-score',
      decision: 'BLOCK',
      score: 25,
      metadata: {
        trustScore: 25,
        reason: 'Score de confiance faible',
      },
    },
  ] as DetectorResult[],
  executionTimeMs: 120,
  createdAt: new Date(),
};
```

**Mock Data Structure - ai_explanations**:
```typescript
const mockAIExplanation = {
  id: 'expl_001',
  detectionId: 'det_001',
  organizationId: 'org_001',
  explanation: 'Cette transaction a √©t√© signal√©e car plusieurs facteurs de risque ont √©t√© d√©tect√©s. Le d√©tecteur de v√©locit√© a identifi√© un nombre anormalement √©lev√© de transactions (10) dans un court laps de temps (1 heure), ce qui sugg√®re un possible test de carte. De plus, le score de confiance du client est faible (25/100), indiquant un historique de transactions suspectes.',
  generatedAt: new Date(),
  model: 'gpt-4o-mini',
  tokensUsed: 150,
  latency: 1800, // 1.8s
  triggerJobId: 'job_trigger_001',
  createdAt: new Date(),
};
```

**Mock LLM Response**:
```typescript
// Mock OpenAI API response
const mockOpenAIResponse = {
  choices: [
    {
      message: {
        content: 'Cette transaction a √©t√© signal√©e car...',
      },
    },
  ],
  usage: {
    total_tokens: 150,
    prompt_tokens: 100,
    completion_tokens: 50,
  },
};
```

---

## Validation Report

**Validated by**: Sarah (Product Owner)  
**Validation Date**: 2026-01-26  
**Validation Status**: ‚úÖ **APPROVED - Ready for Implementation**

### Validation Summary

**Template Compliance**: ‚úÖ All required sections present, no placeholders  
**File Structure**: ‚úÖ Clear file paths and source tree context  
**UI Completeness**: ‚úÖ Design specifications added (colors, responsive, accessibility, SSE integration)  
**AC Coverage**: ‚úÖ All 8 acceptance criteria covered by tasks  
**Security**: ‚úÖ Zod validation, rate limiting, XSS prevention, Better Auth session (ADR-010 compliant)  
**Task Sequence**: ‚úÖ Logical order with clear dependencies, integration point clarified  
**Anti-Hallucination**: ‚úÖ All technical claims verified against codebase, Trigger.dev integration point corrected  
**Implementation Readiness**: ‚úÖ Self-contained context, clear instructions, ADR references added

### Issues Resolved

**Should-Fix Issues (All Corrected)**:
1. ‚úÖ Trigger.dev integration point clarified (from `saveFraudDetection()` in `detect-fraud.ts`, not webhook route)
2. ‚úÖ AC6 aligned with ADR-008 (SSE with backend polling 5s, not frontend polling 1s)
3. ‚úÖ Zod validation schemas added for API inputs (ADR-010)
4. ‚úÖ XSS sanitization with DOMPurify added for explanation display (ADR-010)
5. ‚úÖ UI design specifications added (colors, responsive, accessibility, SSE integration)
6. ‚úÖ Detailed mock data structure provided for tests (fraud_detections, ai_explanations, LLM responses)
7. ‚úÖ ADR references added (ADR-006, ADR-008, ADR-010)
8. ‚úÖ DetectorResults format detailed with examples

**Critical Issues**: None identified

### Final Assessment

- **Implementation Readiness Score**: 9.5/10
- **Confidence Level**: High
- **Recommendation**: Story is ready for development. All technical details are clear, security requirements are met, integration points are correctly specified, and test data structures are defined.

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-26 | 1.0 | Story created | Sarah (PO) |
| 2026-01-26 | 1.1 | Should-fix corrections: Clarified Trigger.dev integration point, aligned AC6 with ADR-008 (SSE), added Zod validation, XSS sanitization, UI design specs, detailed mock data structure, ADR references | Sarah (PO) |
| 2026-01-26 | 1.2 | Validation completed: Story approved and marked as Ready for implementation | Sarah (PO) |
| 2026-01-26 | 2.0 | Implementation: Tasks 1-7 completed, Task 8 (tests) pending | James (Dev) |

---

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4.5 (via Cursor)

### Debug Log References
N/A

### Completion Notes List
- ‚úÖ Created database schema `ai_explanations` in `packages/database/src/schema/ai-explanations.ts`
- ‚úÖ Generated migration file: `packages/database/drizzle/0002_jittery_hulk.sql`
- ‚úÖ Created Trigger.dev job for async AI explanation generation (AC1, AC2)
- ‚úÖ Integrated job trigger in `saveFraudDetection()` (non-blocking, fire-and-forget)
- ‚úÖ Created API endpoint with Zod validation and rate limiting (AC4)
- ‚úÖ Created UI component with DOMPurify sanitization and SSE integration (AC4, AC5)
- ‚úÖ Implemented fallback template explanations (AC7)
- ‚úÖ Added cost control: rate limiting (10/min), caching similar patterns (AC8)
- ‚úÖ Created integration tests for Trigger.dev job, fallback logic, rate limiting, and caching (AC2, AC7, AC8)
- ‚ö†Ô∏è Note: Migration needs to be applied to database (run `drizzle-kit push` or apply migration)
- ‚ö†Ô∏è Note: Trigger.dev environment variables required (TRIGGER_SECRET_KEY, TRIGGER_PROJECT_ID)
- ‚ö†Ô∏è Note: OpenAI API key required (OPENAI_API_KEY)
- ‚ö†Ô∏è Note: PostHog cost alert (‚Ç¨200/month) requires PostHog integration (deferred)

### File List
**Created:**
- `packages/database/src/schema/ai-explanations.ts` - Database schema for AI explanations
- `apps/web/trigger/client.ts` - Trigger.dev client configuration
- `apps/web/trigger/index.ts` - Trigger.dev jobs export
- `apps/web/trigger/jobs/ai-explanation.job.ts` - Trigger.dev job for AI explanation generation
- `apps/web/lib/openai.ts` - OpenAI client configuration
- `apps/web/lib/ai/explanation-prompt.ts` - Prompt building for LLM
- `apps/web/lib/ai/explanation-templates.ts` - Fallback template explanations
- `apps/web/lib/ai/explanation-cache.ts` - Redis caching for similar detection patterns
- `apps/web/lib/validation/ai-explanations.ts` - Zod validation schemas
- `apps/web/app/api/detections/[id]/explanation/route.ts` - GET explanation endpoint
- `apps/web/components/ai-explanation.tsx` - UI component for explanation display
- `apps/web/trigger/jobs/__tests__/ai-explanation.integration.test.ts` - Integration tests for AI explanation job

**Modified:**
- `packages/database/src/schema/index.ts` - Added export for ai-explanations
- `apps/web/lib/fraud/detect-fraud.ts` - Integrated Trigger.dev job trigger in `saveFraudDetection()`
- `apps/web/lib/rate-limit.ts` - Added explanation generation rate limiter (10/min)
- `apps/web/components/detection-details-dialog.tsx` - Integrated AI explanation component (after Detector Results, before Trust Score)
- `apps/web/package.json` - Added dependency: openai@6.16.0

---

## QA Results

(To be populated by QA agent after testing)
