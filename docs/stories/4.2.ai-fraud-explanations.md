# Story 4.2: Explications IA des DÃ©cisions de Fraude

**Epic**: Epic 4 - SystÃ¨me de DÃ©cisions AssistÃ© par IA  
**Story Points**: 8  
**Status**: ðŸ“‹ Draft

---

## Story

**As a** merchant,  
**I want** to understand why a transaction was flagged as fraudulent in plain French language,  
**so that** I can make informed decisions and learn from detection patterns.

---

## Acceptance Criteria

1. **AC1**: Explanation generated asynchronously after detection (non-blocking via Trigger.dev job) - webhook returns <250ms, explanation generated in background
2. **AC2**: LLM API call (OpenAI GPT-4o-mini primary, Anthropic Claude backup) with detection context from `fraud_detections.detectorResults`
3. **AC3**: Explanation includes: which detectors triggered (from `detectorResults`), why they flagged (detector scores and reasons), risk factors identified (riskScore, decision)
4. **AC4**: Explanation displayed in `detection-details-dialog.tsx` with loading skeleton while generating, "Generating explanation..." badge if pending
5. **AC5**: Language: French (LLM prompt in French, system message: "Tu es un expert..."), fallback to English template if LLM unavailable
6. **AC6**: Performance: Generation <2s async (Trigger.dev job latency), displayed progressively (SSE update or polling every 1s)
7. **AC7**: Error handling: Fallback to template-based explanation if LLM fails (from `lib/ai/explanation-templates.ts`) - lists detector names and scores
8. **AC8**: Cost control: Rate limiting (10 explanations/minute per organization via Redis), caching similar detections (same detector pattern â†’ reuse explanation)

---

## Tasks / Subtasks

- [ ] **Task 1**: Create Trigger.dev job for AI explanation (AC1, AC2)
  - [ ] Create `trigger/jobs/ai-explanation.job.ts` (ADR-006)
  - [ ] Job accepts: `detectionId`, `context`, `factors`, `priority`
  - [ ] Build prompt with detection context (detector results, scores, metadata)
  - [ ] Call OpenAI/Anthropic API with French language instruction
  - [ ] Store explanation in `ai_explanations` table

- [ ] **Task 2**: Database schema for AI explanations (AC3)
  - [ ] Create `ai_explanations` table migration (Drizzle)
  - [ ] Fields: `id`, `detectionId`, `explanation` (text), `generatedAt`, `model`, `tokensUsed`, `latency`, `triggerJobId`
  - [ ] Add foreign key to `fraud_detections` table

- [ ] **Task 3**: Trigger explanation job from webhook (AC1)
  - [ ] Update `app/api/webhooks/stripe/route.ts`
  - [ ] After detection stored in `fraud_detections` table, trigger `generateAIExplanation.trigger()` (non-blocking)
  - [ ] Set priority: HIGH for BLOCK, NORMAL for REVIEW/ALLOW
  - [ ] Pass detection context: `detectionId`, `detectorResults`, `riskScore`, `decision`, `customerEmail`, `amount`, `cardCountry`, `customerIp`
  - [ ] Return webhook response immediately (<250ms) - don't wait for explanation generation

- [ ] **Task 4**: API endpoint to fetch explanation (AC4)
  - [ ] Create `GET /api/detections/[id]/explanation` endpoint
  - [ ] Return explanation if generated, or status "pending" if still generating
  - [ ] Return fallback template explanation if LLM failed

- [ ] **Task 5**: UI component for explanation display (AC4, AC5)
  - [ ] Create `components/ai-explanation.tsx` component
  - [ ] Show loading skeleton while generating
  - [ ] Display explanation in French (with language indicator)
  - [ ] Integrate into `detection-details-dialog.tsx`
  - [ ] Show "Generating explanation..." badge if pending

- [ ] **Task 6**: Fallback template explanations (AC7)
  - [ ] Create `lib/ai/explanation-templates.ts`
  - [ ] Template-based explanation: List detectors triggered + scores
  - [ ] Use if LLM fails or unavailable
  - [ ] Format: "Cette transaction a Ã©tÃ© signalÃ©e par: [detector names]. Score de risque: [score]"

- [ ] **Task 7**: Cost control & caching (AC8)
  - [ ] Rate limiting: Max 10 explanations/minute per organization
  - [ ] Cache similar detections (same detector pattern) â†’ reuse explanation
  - [ ] Monitor API costs (PostHog event: `ai_explanation_generated`, `tokens_used`)
  - [ ] Alert if monthly cost >â‚¬200

- [ ] **Task 8**: Integration tests (AC2, AC7)
  - [ ] Test Trigger.dev job execution (mocked LLM)
  - [ ] Test fallback to template if LLM fails
  - [ ] Test rate limiting logic
  - [ ] Test explanation display in UI

---

## Dependencies

**Depends on**:
- Epic 1: `fraud_detections` table with `detectorResults` field
- Epic 3: Trigger.dev configured (ADR-006), Redis for rate limiting
- Infrastructure: OpenAI/Anthropic API keys configured (see `docs/epics/epic-4-infrastructure-setup.md`)

**Blocks**:
- None (can be developed independently)

**Can be developed in parallel with**:
- Story 4.1 (Suggestions) - no shared dependencies
- Story 4.3 (Rule recommendations) - no shared dependencies
- Story 4.4 (Feedback loop) - no shared dependencies

---

## Dev Notes

### Relevant Architecture

**Trigger.dev Job** (ADR-006):
```typescript
// trigger/jobs/ai-explanation.job.ts
import { task } from "@trigger.dev/sdk/v3";
import { openai } from "@/lib/openai";

export const generateAIExplanation = task({
  id: "generate-ai-explanation",
  retry: { maxAttempts: 3, factor: 2 },
  queue: { name: "ai-explanation", concurrencyLimit: 10 },
  run: async (payload: {
    detectionId: string;
    context: TransactionContext;
    factors: FraudFactor[];
    priority: 'HIGH' | 'NORMAL';
  }) => {
    const prompt = buildExplanationPrompt(payload.context, payload.factors);
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        { role: "system", content: "Tu es un expert en dÃ©tection de fraude..." },
        { role: "user", content: prompt },
      ],
      temperature: 0.3,
    });
    
    const explanation = completion.choices[0].message.content || "";
    
    // Store in ai_explanations table (not in fraud_detections directly)
    await db.insert(aiExplanations).values({
      detectionId: payload.detectionId,
      organizationId: payload.context.organizationId,
      explanation,
      model: "gpt-4o-mini",
      tokensUsed: completion.usage?.total_tokens,
      latency: Date.now() - startTime,
      triggerJobId: run.id,
    });
    
    return { success: true, explanation };
  },
});
```

**Prompt Template**:
```
Tu es un expert en dÃ©tection de fraude. Analyse cette dÃ©tection et explique en franÃ§ais (2-3 phrases) pourquoi cette transaction a Ã©tÃ© signalÃ©e.

Transaction:
- Montant: {amount} {currency}
- Client: {customerEmail}
- Pays carte: {cardCountry}
- IP: {customerIp}

DÃ©tecteurs dÃ©clenchÃ©s:
{detector_results_formatted}

Score de risque: {riskScore}/100
DÃ©cision: {decision}

Explique en franÃ§ais pourquoi cette transaction est suspecte, en mentionnant les facteurs de risque principaux. Sois concis (2-3 phrases maximum).
```

**Detector Results Format**:
```typescript
// Format detector results for prompt
const detectorResultsFormatted = detectorResults
  .map(d => `- ${d.detectorId}: Score ${d.score} (${d.reason})`)
  .join('\n');
```

**Database Schema**:
```typescript
// packages/database/src/schema/ai-explanations.ts
import { pgTable, text, timestamp, integer, index } from "drizzle-orm/pg-core";
import { fraudDetections } from "./fraud-detections";
import { organizations } from "./organizations";

export const aiExplanations = pgTable('ai_explanations', {
  id: text('id').primaryKey().$defaultFn(() => crypto.randomUUID()),
  detectionId: text('detection_id')
    .notNull()
    .references(() => fraudDetections.id, { onDelete: 'cascade' }),
  organizationId: text('organization_id')
    .notNull()
    .references(() => organizations.id, { onDelete: 'cascade' }),
  explanation: text('explanation').notNull(),
  generatedAt: timestamp('generated_at').defaultNow().notNull(),
  model: text('model').notNull(), // 'gpt-4o-mini' or 'claude-3-haiku'
  tokensUsed: integer('tokens_used'),
  latency: integer('latency'), // ms
  triggerJobId: text('trigger_job_id'),
  createdAt: timestamp('created_at').defaultNow().notNull(),
});

// Indexes for performance
export const aiExplanationsIndexes = {
  detectionId: index('ai_explanations_detection_id_idx').on(aiExplanations.detectionId),
  organizationId: index('ai_explanations_organization_id_idx').on(aiExplanations.organizationId),
};
```

**Integration Points**:
- Uses Trigger.dev for async processing (ADR-006)
- Integrates with `detection-details-dialog.tsx` (Epic 2)
- Uses existing `fraud_detections` table (Epic 1)
- Uses Redis for rate limiting (Epic 3)

**Cost Control Strategy**:
- Use GPT-4o-mini (cheaper than GPT-4)
- Cache explanations for similar detections (same detector pattern)
- Rate limit: 10/minute per organization
- Monitor costs via PostHog events
- Fallback to templates if budget exceeded

### Source Tree Context

```
apps/web/
â”œâ”€â”€ trigger/
â”‚   â””â”€â”€ jobs/
â”‚       â””â”€â”€ ai-explanation.job.ts      # Trigger.dev job
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ai/
â”‚       â”œâ”€â”€ explanation-prompt.ts      # Prompt building
â”‚       â””â”€â”€ explanation-templates.ts    # Fallback templates
â”œâ”€â”€ app/
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ detections/
â”‚           â””â”€â”€ [id]/
â”‚               â””â”€â”€ explanation/
â”‚                   â””â”€â”€ route.ts       # GET explanation
â””â”€â”€ components/
    â”œâ”€â”€ ai-explanation.tsx             # Explanation display component
    â””â”€â”€ detection-details-dialog.tsx   # Integrate explanation
```

---

## Testing

### Unit Tests
- **File**: `apps/web/lib/ai/explanation-prompt.test.ts`
- **Tests**:
  - Prompt building with detection context
  - Template fallback generation
  - Rate limiting logic

### Integration Tests
- **File**: `apps/web/trigger/jobs/__tests__/ai-explanation.integration.test.ts`
- **Tests**:
  - Trigger.dev job execution (mocked LLM)
  - Database storage of explanation
  - Fallback to template on LLM failure

### E2E Tests
- **File**: `e2e/ai-explanation.spec.ts` (Playwright)
- **Tests**:
  - Explanation appears in detection dialog
  - Loading state while generating
  - Fallback template displayed if LLM fails

### Testing Standards
- Framework: Vitest (unit), Playwright (E2E)
- Coverage target: â‰¥80% for explanation logic
- Mock LLM API calls (deterministic tests)
- Test error scenarios (LLM timeout, rate limit)

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-26 | 1.0 | Story created | Sarah (PO) |

---

## Dev Agent Record

(To be populated during implementation)

---

## QA Results

(To be populated by QA agent after testing)
